{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b54a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.v2 as v2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465ec41",
   "metadata": {},
   "source": [
    "### Get the data for the MNIST dataset\n",
    "* `10000 samples for train set`\n",
    "* `5000 samples for test set`\n",
    "\n",
    "Both the sets will be balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c3cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform =v2.Compose([\n",
    "    v2.ToImage,\n",
    "    v2.ToDtype(torch.float,scale=True)\n",
    "])\n",
    "\n",
    "train = MNIST('./mnist_dataset',train=True,download=False,transform=transform)\n",
    "test = MNIST('./mnist_dataset',train=False,download=False,transform = transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f35ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449508f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train.classes\n",
    "class_names\n",
    "classes= torch.tensor([0,1,2,3,4,5,6,7,8,9])\n",
    "X_train,y_train = train.data,train.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d16d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_k_per_class(X, y, classes, k):\n",
    "    x_samples = []\n",
    "    y_samples = []\n",
    "\n",
    "    for cls in classes:\n",
    "        indices = (y == cls).nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        if len(indices) < k:\n",
    "            raise ValueError(f\"Not enough samples in class {cls} to sample {k} items.\")\n",
    "\n",
    "        chosen = indices[torch.randperm(len(indices))[:k]]\n",
    "\n",
    "        x_samples.append(X[chosen])\n",
    "        y_samples.append(y[chosen])\n",
    "\n",
    "    X_out = torch.cat(x_samples, dim=0)\n",
    "    y_out = torch.cat(y_samples, dim=0)\n",
    "\n",
    "    perm = torch.randperm(len(y_out))\n",
    "    return X_out[perm], y_out[perm]\n",
    "def count_trainable_layers(model):\n",
    "    return sum(1 for m in model.modules() if any(p.requires_grad for p in m.parameters()))\n",
    "X_train,y_train = sample_k_per_class(X_train,y_train,classes,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a73c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = test.data,test.targets\n",
    "X_test,y_test = sample_k_per_class(X_test,y_test,classes,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea1323cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.type(torch.float)\n",
    "X_test = X_test.type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7bd1730",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.unsqueeze(X_train,dim=1)\n",
    "X_test = torch.unsqueeze(X_test,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dd2acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = X_train.to(device),X_test.to(device)\n",
    "y_train,y_test = y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e925f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConvNetwork(nn.Module):\n",
    "    def __init__(self,config,width):\n",
    "        super().__init__()\n",
    "        self.layers  = nn.ModuleList()\n",
    "        for in_ch,out_ch in config:\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(in_ch,out_ch,kernel_size=3,padding='same')\n",
    "            )\n",
    "        self.final_width = width - len(config)\n",
    "        last_out_channels = config[-1][1]\n",
    "        self.maxpool = nn.MaxPool2d(2,1)\n",
    "        self.l1 = nn.Linear(last_out_channels*self.final_width*self.final_width,10) \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x= F.relu(x)\n",
    "            x = self.maxpool(x)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "        \n",
    "        x = self.l1(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d6407d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ls = []\n",
    "num_models = 3\n",
    "layers = 5\n",
    "for i in range(num_models):\n",
    "    hold = [[1,3]]\n",
    "    for _ in range(layers-1):\n",
    "        hold.append([3,3])\n",
    "    \n",
    "    config_ls.append(hold)\n",
    "    layers += 5\n",
    "\n",
    "models = []\n",
    "optimizers = []\n",
    "schedulers = []\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "for config in config_ls:\n",
    "    model_hold = MyConvNetwork(config,width=28).to(device)\n",
    "    models.append(model_hold)\n",
    "    optimizers.append(torch.optim.Adam(params = model_hold.parameters(),lr=0.01))\n",
    "    schedulers.append(torch.optim.lr_scheduler.StepLR(optimizers[-1], step_size=10, gamma=0.1))\n",
    "\n",
    "model_losses_train = []\n",
    "model_accuracy_train = []\n",
    "model_losses_test = []\n",
    "model_accuracy_test = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8552e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models,optimizers, schedulers\n",
    "epochs = 100\n",
    "\n",
    "for current_model in range(num_models):\n",
    "    print(\"-----------------------------------------------Current Model \",current_model)\n",
    "    train_loss_ls = []\n",
    "    train_acc_ls = []\n",
    "    test_loss_ls = []\n",
    "    test_acc_ls = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        models[current_model].train()\n",
    "        y_pred_train = models[current_model](X_train)\n",
    "        y_pred_labels = y_pred_train.argmax(dim=1)\n",
    "        correct = (y_pred_labels == y_train).sum().item()\n",
    "        acc = 100 * correct / len(y_train)\n",
    "\n",
    "        loss = loss_fn(y_pred_train,y_train)\n",
    "\n",
    "        train_loss_ls.append(loss.item())\n",
    "        train_acc_ls.append(acc)\n",
    "\n",
    "        optimizers[current_model].zero_grad()\n",
    "        loss.backward()\n",
    "        optimizers[current_model].step()\n",
    "        schedulers[current_model].step()\n",
    "\n",
    "        models[current_model].eval()\n",
    "        with torch.inference_mode():\n",
    "            y_pred_test = models[current_model](X_test)\n",
    "            loss = loss_fn(y_pred_test,y_test)\n",
    "            y_pred_labels = y_pred_test.argmax(dim=1)\n",
    "            correct = (y_pred_labels == y_test).sum().item()\n",
    "            acc = 100 * correct / len(y_test)\n",
    "\n",
    "            test_loss_ls.append(loss.item())\n",
    "            test_acc_ls.append(acc)\n",
    "        if epoch%5==0:\n",
    "            print(f\"{epoch} :: Train loss : {train_loss_ls[-1]} Train Acc : {train_acc_ls[-1]} -------------------------- Test loss : {test_loss_ls[-1]}  Test Acc : {test_acc_ls[-1]}\")\n",
    "\n",
    "    model_losses_train.append(train_loss_ls)\n",
    "    model_losses_test.append(test_loss_ls)\n",
    "    model_accuracy_train.append(train_acc_ls)\n",
    "    model_accuracy_test.append(test_acc_ls)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb5ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = model_accuracy_train\n",
    "colors = ['r','g','b','yellow','orange']\n",
    "y_label = 'Loss'\n",
    "x_label = 'epochs'\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "for idx,l in enumerate(ls):\n",
    "    plt.plot(range(len(l)),l,c = colors[idx],label= f\"Model {idx} {y_label}\")\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1473aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91aabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48358915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097b500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ce57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
