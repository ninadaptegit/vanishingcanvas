{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5b54a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.v2 as v2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465ec41",
   "metadata": {},
   "source": [
    "### Get the data for the MNIST dataset\n",
    "* `10000 samples for train set`\n",
    "* `5000 samples for test set`\n",
    "\n",
    "Both the sets will be balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c3cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform =v2.Compose([\n",
    "    v2.ToImage,\n",
    "    v2.ToDtype(torch.float,scale=True)\n",
    "])\n",
    "\n",
    "train = MNIST('./mnist_dataset',train=True,download=False,transform=transform)\n",
    "test = MNIST('./mnist_dataset',train=False,download=False,transform = transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "18f35ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "449508f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train.classes\n",
    "class_names\n",
    "classes= torch.tensor([0,1,2,3,4,5,6,7,8,9])\n",
    "X_train,y_train = train.data,train.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f2d16d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_k_per_class(X, y, classes, k):\n",
    "    x_samples = []\n",
    "    y_samples = []\n",
    "\n",
    "    for cls in classes:\n",
    "        indices = (y == cls).nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        if len(indices) < k:\n",
    "            raise ValueError(f\"Not enough samples in class {cls} to sample {k} items.\")\n",
    "\n",
    "        chosen = indices[torch.randperm(len(indices))[:k]]\n",
    "\n",
    "        x_samples.append(X[chosen])\n",
    "        y_samples.append(y[chosen])\n",
    "\n",
    "    X_out = torch.cat(x_samples, dim=0)\n",
    "    y_out = torch.cat(y_samples, dim=0)\n",
    "\n",
    "    perm = torch.randperm(len(y_out))\n",
    "    return X_out[perm], y_out[perm]\n",
    "def count_trainable_layers(model):\n",
    "    return sum(1 for m in model.modules() if any(p.requires_grad for p in m.parameters()))\n",
    "X_train,y_train = sample_k_per_class(X_train,y_train,classes,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a73c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test = test.data,test.targets\n",
    "X_test,y_test = sample_k_per_class(X_test,y_test,classes,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ea1323cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.type(torch.float)\n",
    "X_test = X_test.type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7dd2acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = X_train.to(device),X_test.to(device)\n",
    "y_train,y_test = y_train.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5e925f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConvNetwork(nn.Module):\n",
    "    def __init__(self,config,width):\n",
    "        super().__init__()\n",
    "        self.layers  = nn.ModuleList()\n",
    "        for in_ch,out_ch in config:\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(in_ch,out_ch,kernel_size=3,padding='same')\n",
    "            )\n",
    "        self.final_width = width - len(config)\n",
    "        last_out_channels = config[-1][1]\n",
    "        self.maxpool = nn.MaxPool2d(2,1)\n",
    "        self.l1 = nn.Linear(last_out_channels*self.final_width*self.final_width,10) \n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x= F.relu(x)\n",
    "            x = self.maxpool(x)\n",
    "        \n",
    "        x = torch.flatten(x,1)\n",
    "        \n",
    "        x = self.l1(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df99b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3954, -0.5699,  0.2147, -0.2486,  0.2880, -0.0752, -0.4586, -0.3145,\n",
       "         -0.3568,  0.2415]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model(torch.unsqueeze(X_train[0],dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b6993ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MyConvNetwork([[1,3],[3,8],[8,16],[16,24],[24,32],[32,24],[24,16],[16,8],[8,3],[3,3]],width=28).to(device)\n",
    "# opt = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "# sch = torch.optim.lr_scheduler.StepLR(opt, step_size=10, gamma=0.1)\n",
    "# loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3a64b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(50):\n",
    "    \n",
    "#     model.train()\n",
    "#     y_pred_train = model(X_train)\n",
    "#     y_pred_labels = y_pred_train.argmax(dim=1)\n",
    "#     correct = (y_pred_labels == y_train).sum().item()\n",
    "#     trainacc = 100 * correct / len(y_train)\n",
    "\n",
    "#     loss = loss_fn(y_pred_train,y_train)\n",
    "#     trainloss = loss.item()\n",
    "#     opt.zero_grad()\n",
    "#     loss.backward()\n",
    "\n",
    "#     for name, param in model.named_parameters():\n",
    "#         if param.grad is not None:\n",
    "#             grad_norm = param.grad.data.norm(2).item()\n",
    "#             if grad_norm < 1e-8 or grad_norm > 1e2:\n",
    "#                 print(\"Vanishing or explosion of gradient encountered\")\n",
    "#     opt.step()\n",
    "#     sch.step()\n",
    "\n",
    "\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.inference_mode():\n",
    "#         y_pred_test = model(X_test)\n",
    "#         loss = loss_fn(y_pred_test,y_test)\n",
    "#         y_pred_labels = y_pred_test.argmax(dim=1)\n",
    "#         correct = (y_pred_labels == y_test).sum().item()\n",
    "#         testacc = 100 * correct / len(y_test)\n",
    "\n",
    "#         testloss = loss.item()\n",
    "    \n",
    "#     if epoch%5==0:\n",
    "#         print(f\"{epoch} :: Train loss : {trainloss} Train Acc : {trainacc} -------------------------- Test loss : {testloss}  Test Acc : {testacc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4d6407d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ls = []\n",
    "num_models = 3\n",
    "layers = 5\n",
    "for i in range(num_models):\n",
    "    hold = [[1,3]]\n",
    "    for _ in range(layers-1):\n",
    "        hold.append([3,3])\n",
    "    \n",
    "    config_ls.append(hold)\n",
    "    layers += 5\n",
    "\n",
    "models = []\n",
    "optimizers = []\n",
    "schedulers = []\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "for config in config_ls:\n",
    "    model_hold = MyConvNetwork(config,width=28).to(device)\n",
    "    models.append(model_hold)\n",
    "    optimizers.append(torch.optim.Adam(params = model_hold.parameters(),lr=0.01))\n",
    "    schedulers.append(torch.optim.lr_scheduler.StepLR(optimizers[-1], step_size=10, gamma=0.1))\n",
    "\n",
    "model_losses_train = []\n",
    "model_accuracy_train = []\n",
    "model_losses_test = []\n",
    "model_accuracy_test = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d2a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0204,  0.0118,  0.0175,  0.0179, -0.0210, -0.0068,  0.0113, -0.0140,\n",
       "         -0.0102,  0.0129]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47db5bc",
   "metadata": {},
   "source": [
    "## I will try 2 approaches\n",
    "1) Train all the models for the same epochs and compare the performance vs time\n",
    "2) Train all the models till their performance flatlines and compare their performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c8552e3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.47 GiB is allocated by PyTorch, and 279.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[199], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     11\u001b[0m     models[current_model]\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 12\u001b[0m     y_pred_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     y_pred_labels \u001b[38;5;241m=\u001b[39m y_pred_train\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m     correct \u001b[38;5;241m=\u001b[39m (y_pred_labels \u001b[38;5;241m==\u001b[39m y_train)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\HP\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\HP\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[195], line 16\u001b[0m, in \u001b[0;36mMyConvNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(x)\n\u001b[1;32m---> 16\u001b[0m     x\u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\.conda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\functional.py:1704\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1702\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1704\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1705\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 72.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.47 GiB is allocated by PyTorch, and 279.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# models,optimizers, schedulers\n",
    "current_model = 0\n",
    "epochs = 100\n",
    "train_loss_ls = []\n",
    "train_acc_ls = []\n",
    "test_loss_ls = []\n",
    "test_acc_ls = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    models[current_model].train()\n",
    "    y_pred_train = models[current_model](X_train)\n",
    "    y_pred_labels = y_pred_train.argmax(dim=1)\n",
    "    correct = (y_pred_labels == y_train).sum().item()\n",
    "    acc = 100 * correct / len(y_train)\n",
    "\n",
    "    loss = loss_fn(y_pred_train,y_train)\n",
    "\n",
    "    train_loss_ls.append(loss.item())\n",
    "    train_acc_ls.append(acc)\n",
    "\n",
    "    optimizers[current_model].zero_grad()\n",
    "    loss.backward()\n",
    "    optimizers[current_model].step()\n",
    "    schedulers[current_model].step()\n",
    "\n",
    "    models[current_model].eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred_test = models[current_model](X_test)\n",
    "        loss = loss_fn(y_pred_test,y_test)\n",
    "        y_pred_labels = y_pred_test.argmax(dim=1)\n",
    "        correct = (y_pred_labels == y_test).sum().item()\n",
    "        acc = 100 * correct / len(y_test)\n",
    "\n",
    "        test_loss_ls.append(loss.item())\n",
    "        test_acc_ls.append(acc)\n",
    "    if epoch%5==0:\n",
    "        print(f\"{epoch} :: Train loss : {train_loss_ls[-1]} Train Acc : {train_acc_ls[-1]} -------------------------- Test loss : {test_loss_ls[-1]}  Test Acc : {test_acc_ls[-1]}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f089af9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11236888064"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9beb5ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_losses_train.append(train_loss_ls)\n",
    "model_losses_test.append(test_loss_ls)\n",
    "model_accuracy_train.append(train_acc_ls)\n",
    "model_accuracy_test.append(test_acc_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91aabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = model_losses_train\n",
    "colors = ['r','g','b','yellow','orange']\n",
    "y_label = 'Loss'\n",
    "x_label = 'epochs'\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
